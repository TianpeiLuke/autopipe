{
  "script_name": "dummy_training",
  "level1": {
    "passed": true,
    "issues": [],
    "script_analysis": {
      "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/dummy_training.py",
      "path_references": [
        "path='\\nDummyTraining Processing Script\\n\\nThis script validates, unpacks a pretrained model.tar.gz file, adds a hyperparameters.json file \\ninside it, then repacks it and outputs to the destination. It serves as a dummy training step \\nthat skips actual training and integrates with downstream MIMS packaging and payload steps.\\n' line_number=2 context='#!/usr/bin/env python\\n>>> \"\"\"\\nDummyTraining Processing Script\\n' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/model/model.tar.gz' line_number=33 context='# - hyperparameters_s3_uri: \"/opt/ml/processing/input/config/hyperparameters.json\"\\n# - model_input: \"/opt/ml/processing/output/model\" (aligns with packaging step dependency)\\n>>> MODEL_INPUT_PATH = \"/opt/ml/processing/input/model/model.tar.gz\"\\nHYPERPARAMS_INPUT_PATH = \"/opt/ml/processing/input/config/hyperparameters.json\"\\nMODEL_OUTPUT_DIR = \"/opt/ml/processing/output/model\"' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/config/hyperparameters.json' line_number=34 context='# - model_input: \"/opt/ml/processing/output/model\" (aligns with packaging step dependency)\\nMODEL_INPUT_PATH = \"/opt/ml/processing/input/model/model.tar.gz\"\\n>>> HYPERPARAMS_INPUT_PATH = \"/opt/ml/processing/input/config/hyperparameters.json\"\\nMODEL_OUTPUT_DIR = \"/opt/ml/processing/output/model\"\\n' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/model' line_number=35 context='MODEL_INPUT_PATH = \"/opt/ml/processing/input/model/model.tar.gz\"\\nHYPERPARAMS_INPUT_PATH = \"/opt/ml/processing/input/config/hyperparameters.json\"\\n>>> MODEL_OUTPUT_DIR = \"/opt/ml/processing/output/model\"\\n\\ndef validate_model(input_path: Path) -> bool:' is_hardcoded=True construction_method=None",
        "path='.tar.gz' line_number=54 context='    \\n    # Check file extension\\n>>>     if not input_path.suffix == \\'.tar.gz\\' and not str(input_path).endswith(\\'.tar.gz\\'):\\n        raise ValueError(f\"Expected a .tar.gz file, but got: {input_path} (ERROR_CODE: INVALID_FORMAT)\")\\n    ' is_hardcoded=True construction_method=None",
        "path='.tar.gz' line_number=54 context='    \\n    # Check file extension\\n>>>     if not input_path.suffix == \\'.tar.gz\\' and not str(input_path).endswith(\\'.tar.gz\\'):\\n        raise ValueError(f\"Expected a .tar.gz file, but got: {input_path} (ERROR_CODE: INVALID_FORMAT)\")\\n    ' is_hardcoded=True construction_method=None",
        "path='Ensure a directory exists, creating it if necessary.' line_number=70 context='\\ndef ensure_directory(directory: Path):\\n>>>     \"\"\"Ensure a directory exists, creating it if necessary.\"\"\"\\n    try:\\n        directory.mkdir(parents=True, exist_ok=True)' is_hardcoded=True construction_method=None",
        "path='Extract a tar file to the specified path.' line_number=80 context='\\ndef extract_tarfile(tar_path: Path, extract_path: Path):\\n>>>     \"\"\"Extract a tar file to the specified path.\"\"\"\\n    logger.info(f\"Extracting tar file: {tar_path} to {extract_path}\")\\n    ' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=95 context='                size_mb = member.size / 1024 / 1024\\n                total_size += size_mb\\n>>>                 logger.info(f\"  {member.name} ({size_mb:.2f}MB)\")\\n            logger.info(f\"Total size in tar: {total_size:.2f}MB\")\\n            ' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=96 context='                total_size += size_mb\\n                logger.info(f\"  {member.name} ({size_mb:.2f}MB)\")\\n>>>             logger.info(f\"Total size in tar: {total_size:.2f}MB\")\\n            \\n            logger.info(f\"Extracting to: {extract_path}\")' is_hardcoded=True construction_method=None",
        "path='Create a tar file from the contents of a directory.' line_number=108 context='\\ndef create_tarfile(output_tar_path: Path, source_dir: Path):\\n>>>     \"\"\"Create a tar file from the contents of a directory.\"\"\"\\n    logger.info(f\"Creating tar file: {output_tar_path} from {source_dir}\")\\n    ' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=124 context='                    total_size += size_mb\\n                    files_added += 1\\n>>>                     logger.info(f\"Adding to tar: {arcname} ({size_mb:.2f}MB)\")\\n                    tar.add(item, arcname=arcname)\\n        ' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=129 context='        logger.info(f\"Tar creation summary:\")\\n        logger.info(f\"  Files added: {files_added}\")\\n>>>         logger.info(f\"  Total uncompressed size: {total_size:.2f}MB\")\\n        \\n        if output_tar_path.exists():' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=133 context='        if output_tar_path.exists():\\n            compressed_size = output_tar_path.stat().st_size / 1024 / 1024\\n>>>             logger.info(f\"  Compressed tar size: {compressed_size:.2f}MB\")\\n            logger.info(f\"  Compression ratio: {compressed_size/total_size:.2%}\")\\n        ' is_hardcoded=True construction_method=None",
        "path='.2%' line_number=134 context='            compressed_size = output_tar_path.stat().st_size / 1024 / 1024\\n            logger.info(f\"  Compressed tar size: {compressed_size:.2f}MB\")\\n>>>             logger.info(f\"  Compression ratio: {compressed_size/total_size:.2%}\")\\n        \\n    except Exception as e:' is_hardcoded=True construction_method=None",
        "path='Copy a file and ensure the destination directory exists.' line_number=141 context='\\ndef copy_file(src: Path, dst: Path):\\n>>>     \"\"\"Copy a file and ensure the destination directory exists.\"\"\"\\n    logger.info(f\"Copying file: {src} to {dst}\")\\n    ' is_hardcoded=True construction_method=None",
        "path='hyperparameters.json' line_number=193 context='        \\n        # Copy hyperparameters.json to the working directory\\n>>>         hyperparams_dest = working_dir / \"hyperparameters.json\"\\n        copy_file(hyperparams_path, hyperparams_dest)\\n        ' is_hardcoded=True construction_method=None",
        "path='model.tar.gz' line_number=200 context='        \\n        # Create the output model.tar.gz\\n>>>         output_path = output_dir / \"model.tar.gz\"\\n        create_tarfile(output_path, working_dir)\\n        ' is_hardcoded=True construction_method=None",
        "path='No hyperparameters file found. Falling back to simple copy mode.' line_number=234 context='        else:\\n            # For backward compatibility: just validate and copy the model\\n>>>             logger.info(\"No hyperparameters file found. Falling back to simple copy mode.\")\\n            validate_model(model_path)\\n            output_path = output_dir / \"model.tar.gz\"' is_hardcoded=True construction_method=None",
        "path='model.tar.gz' line_number=236 context='            logger.info(\"No hyperparameters file found. Falling back to simple copy mode.\")\\n            validate_model(model_path)\\n>>>             output_path = output_dir / \"model.tar.gz\"\\n            ensure_directory(output_dir)\\n            copy_file(model_path, output_path)' is_hardcoded=True construction_method=None"
      ],
      "env_var_accesses": [],
      "imports": [
        "module_name='argparse' import_alias=None line_number=10 is_from_import=False imported_items=[]",
        "module_name='json' import_alias=None line_number=11 is_from_import=False imported_items=[]",
        "module_name='logging' import_alias=None line_number=12 is_from_import=False imported_items=[]",
        "module_name='os' import_alias=None line_number=13 is_from_import=False imported_items=[]",
        "module_name='shutil' import_alias=None line_number=14 is_from_import=False imported_items=[]",
        "module_name='sys' import_alias=None line_number=15 is_from_import=False imported_items=[]",
        "module_name='tarfile' import_alias=None line_number=16 is_from_import=False imported_items=[]",
        "module_name='tempfile' import_alias=None line_number=17 is_from_import=False imported_items=[]",
        "module_name='pathlib' import_alias=None line_number=18 is_from_import=True imported_items=['Path']",
        "module_name='traceback' import_alias=None line_number=254 is_from_import=False imported_items=[]"
      ],
      "argument_definitions": [],
      "file_operations": []
    },
    "contract": {
      "entry_point": "dummy_training.py",
      "inputs": {
        "pretrained_model_path": {
          "path": "/opt/ml/processing/input/model/model.tar.gz"
        },
        "hyperparameters_s3_uri": {
          "path": "/opt/ml/processing/input/config/hyperparameters.json"
        }
      },
      "outputs": {
        "model_input": {
          "path": "/opt/ml/processing/output/model"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [],
        "optional": {}
      },
      "description": "Contract for dummy training step that processes a pretrained model.tar.gz by unpacking it, adding a hyperparameters.json file inside, and repacking it for downstream steps",
      "framework_requirements": {
        "boto3": ">=1.26.0",
        "pathlib": ">=1.0.0"
      }
    }
  },
  "level2": {
    "passed": true,
    "issues": [],
    "contract": {
      "entry_point": "dummy_training.py",
      "inputs": {
        "pretrained_model_path": {
          "path": "/opt/ml/processing/input/model/model.tar.gz"
        },
        "hyperparameters_s3_uri": {
          "path": "/opt/ml/processing/input/config/hyperparameters.json"
        }
      },
      "outputs": {
        "model_input": {
          "path": "/opt/ml/processing/output/model"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [],
        "optional": {}
      },
      "description": "Contract for dummy training step that processes a pretrained model.tar.gz by unpacking it, adding a hyperparameters.json file inside, and repacking it for downstream steps",
      "framework_requirements": {
        "boto3": ">=1.26.0",
        "pathlib": ">=1.0.0"
      }
    },
    "specifications": {
      "dummy_training_spec": {
        "step_type": "DummyTraining",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "pretrained_model_path",
            "dependency_type": "processing_output",
            "required": false,
            "compatible_sources": [
              "ProcessingStep",
              "TabularPreprocessing",
              "XGBoostTraining",
              "PytorchTraining"
            ],
            "data_type": "S3Uri",
            "description": "Optional pretrained model path. If not provided, step uploads local model file from config."
          },
          {
            "logical_name": "hyperparameters_s3_uri",
            "dependency_type": "hyperparameters",
            "required": false,
            "compatible_sources": [
              "ProcessingStep",
              "HyperparameterPrep"
            ],
            "data_type": "S3Uri",
            "description": "Optional hyperparameters file. If not provided, step generates hyperparameters from config."
          }
        ],
        "outputs": [
          {
            "logical_name": "model_input",
            "output_type": "model_artifacts",
            "property_path": "properties.ProcessingOutputConfig.Outputs['model_input'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "S3 path to model artifacts with integrated hyperparameters"
          }
        ]
      }
    },
    "unified_specification": {
      "primary_spec": {
        "step_type": "DummyTraining",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "pretrained_model_path",
            "dependency_type": "processing_output",
            "required": false,
            "compatible_sources": [
              "ProcessingStep",
              "TabularPreprocessing",
              "XGBoostTraining",
              "PytorchTraining"
            ],
            "data_type": "S3Uri",
            "description": "Optional pretrained model path. If not provided, step uploads local model file from config."
          },
          {
            "logical_name": "hyperparameters_s3_uri",
            "dependency_type": "hyperparameters",
            "required": false,
            "compatible_sources": [
              "ProcessingStep",
              "HyperparameterPrep"
            ],
            "data_type": "S3Uri",
            "description": "Optional hyperparameters file. If not provided, step generates hyperparameters from config."
          }
        ],
        "outputs": [
          {
            "logical_name": "model_input",
            "output_type": "model_artifacts",
            "property_path": "properties.ProcessingOutputConfig.Outputs['model_input'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "S3 path to model artifacts with integrated hyperparameters"
          }
        ]
      },
      "variants": {
        "training": {
          "step_type": "DummyTraining",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "pretrained_model_path",
              "dependency_type": "processing_output",
              "required": false,
              "compatible_sources": [
                "ProcessingStep",
                "TabularPreprocessing",
                "XGBoostTraining",
                "PytorchTraining"
              ],
              "data_type": "S3Uri",
              "description": "Optional pretrained model path. If not provided, step uploads local model file from config."
            },
            {
              "logical_name": "hyperparameters_s3_uri",
              "dependency_type": "hyperparameters",
              "required": false,
              "compatible_sources": [
                "ProcessingStep",
                "HyperparameterPrep"
              ],
              "data_type": "S3Uri",
              "description": "Optional hyperparameters file. If not provided, step generates hyperparameters from config."
            }
          ],
          "outputs": [
            {
              "logical_name": "model_input",
              "output_type": "model_artifacts",
              "property_path": "properties.ProcessingOutputConfig.Outputs['model_input'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "S3 path to model artifacts with integrated hyperparameters"
            }
          ]
        }
      },
      "unified_dependencies": {
        "pretrained_model_path": {
          "logical_name": "pretrained_model_path",
          "dependency_type": "processing_output",
          "required": false,
          "compatible_sources": [
            "ProcessingStep",
            "TabularPreprocessing",
            "XGBoostTraining",
            "PytorchTraining"
          ],
          "data_type": "S3Uri",
          "description": "Optional pretrained model path. If not provided, step uploads local model file from config."
        },
        "hyperparameters_s3_uri": {
          "logical_name": "hyperparameters_s3_uri",
          "dependency_type": "hyperparameters",
          "required": false,
          "compatible_sources": [
            "ProcessingStep",
            "HyperparameterPrep"
          ],
          "data_type": "S3Uri",
          "description": "Optional hyperparameters file. If not provided, step generates hyperparameters from config."
        }
      },
      "unified_outputs": {
        "model_input": {
          "logical_name": "model_input",
          "output_type": "model_artifacts",
          "property_path": "properties.ProcessingOutputConfig.Outputs['model_input'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "S3 path to model artifacts with integrated hyperparameters"
        }
      },
      "dependency_sources": {
        "pretrained_model_path": [
          "training"
        ],
        "hyperparameters_s3_uri": [
          "training"
        ]
      },
      "output_sources": {
        "model_input": [
          "training"
        ]
      },
      "variant_count": 1
    }
  },
  "level3": {
    "passed": true,
    "issues": [
      {
        "severity": "WARNING",
        "category": "dependency_compatibility",
        "message": "Dependency hyperparameters_s3_uri has low compatibility score: 0.420",
        "details": {
          "logical_name": "hyperparameters_s3_uri",
          "specification": "dummy_training",
          "best_match": {
            "provider": "BatchTransform",
            "output": "transform_output",
            "score": 0.4197368421052632
          },
          "required": false,
          "threshold_info": {
            "mode": "relaxed",
            "thresholds": {
              "pass": "\u2265 0.6",
              "warning": "0.4 - 0.59",
              "error": "0.2 - 0.39",
              "critical": "< 0.2"
            },
            "resolution_threshold": 0.5,
            "description": "Relaxed validation allowing reasonable compatibility matches"
          },
          "score_breakdown": {
            "type_compatibility": 0.2,
            "data_type_compatibility": 0.2,
            "semantic_similarity": 0.019736842105263157,
            "exact_match_bonus": 0.0,
            "source_compatibility": 0.0,
            "keyword_matching": 0.0
          },
          "all_candidates": [
            {
              "provider": "BatchTransform",
              "output": "transform_output",
              "score": 0.4197368421052632
            },
            {
              "provider": "PyTorchModel",
              "output": "model_name",
              "score": 0.31875000000000003
            },
            {
              "provider": "XGBoostModel",
              "output": "model_name",
              "score": 0.31875000000000003
            }
          ]
        },
        "recommendation": "Consider renaming 'hyperparameters_s3_uri' or adding aliases to improve semantic matching; Add 'BatchTransform' to compatible_sources for hyperparameters_s3_uri"
      }
    ],
    "specification": {
      "step_type": "DummyTraining",
      "node_type": "internal",
      "dependencies": [
        {
          "logical_name": "pretrained_model_path",
          "dependency_type": "processing_output",
          "required": false,
          "compatible_sources": [
            "ProcessingStep",
            "TabularPreprocessing",
            "XGBoostTraining",
            "PytorchTraining"
          ],
          "data_type": "S3Uri",
          "description": "Optional pretrained model path. If not provided, step uploads local model file from config."
        },
        {
          "logical_name": "hyperparameters_s3_uri",
          "dependency_type": "hyperparameters",
          "required": false,
          "compatible_sources": [
            "ProcessingStep",
            "HyperparameterPrep"
          ],
          "data_type": "S3Uri",
          "description": "Optional hyperparameters file. If not provided, step generates hyperparameters from config."
        }
      ],
      "outputs": [
        {
          "logical_name": "model_input",
          "output_type": "model_artifacts",
          "property_path": "properties.ProcessingOutputConfig.Outputs['model_input'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "S3 path to model artifacts with integrated hyperparameters"
        }
      ]
    }
  },
  "level4": {
    "passed": true,
    "issues": [],
    "builder_analysis": {
      "config_accesses": [],
      "validation_calls": [],
      "default_assignments": [],
      "class_definitions": [
        {
          "class_name": "DummyTrainingStepBuilder",
          "line_number": 33
        }
      ],
      "method_definitions": [
        {
          "method_name": "__init__",
          "line_number": 36
        },
        {
          "method_name": "validate_configuration",
          "line_number": 72
        },
        {
          "method_name": "_normalize_s3_uri",
          "line_number": 102
        },
        {
          "method_name": "_validate_s3_uri",
          "line_number": 130
        },
        {
          "method_name": "_get_s3_directory_path",
          "line_number": 154
        },
        {
          "method_name": "_upload_model_to_s3",
          "line_number": 178
        },
        {
          "method_name": "_prepare_hyperparameters_file",
          "line_number": 210
        },
        {
          "method_name": "_get_processor",
          "line_number": 282
        },
        {
          "method_name": "_get_environment_variables",
          "line_number": 300
        },
        {
          "method_name": "_get_inputs",
          "line_number": 315
        },
        {
          "method_name": "_get_outputs",
          "line_number": 386
        },
        {
          "method_name": "_get_job_arguments",
          "line_number": 426
        },
        {
          "method_name": "create_step",
          "line_number": 437
        }
      ]
    },
    "config_analysis": {
      "class_name": "DummyTrainingConfig",
      "fields": {
        "processing_entry_point": {
          "type": "<class 'str'>",
          "required": false
        },
        "pretrained_model_path": {
          "type": "<class 'str'>",
          "required": false
        },
        "hyperparameters": {
          "type": "<class 'src.cursus.core.base.hyperparameters_base.ModelHyperparameters'>",
          "required": false
        },
        "hyperparameters_s3_uri": {
          "type": "typing.Optional[str]",
          "required": false
        }
      },
      "required_fields": [],
      "optional_fields": [
        "hyperparameters",
        "hyperparameters_s3_uri",
        "pretrained_model_path",
        "processing_entry_point"
      ],
      "default_values": {
        "aws_region": "<property>",
        "effective_instance_type": "<property>",
        "effective_source_dir": "<property>",
        "model_computed_fields": {},
        "model_config": {
          "arbitrary_types_allowed": true,
          "extra": "allow",
          "protected_namespaces": [],
          "validate_assignment": true
        },
        "model_extra": "<property>",
        "model_fields": {
          "author": "annotation=str required=True description='Author or owner of the pipeline.'",
          "bucket": "annotation=str required=True description='S3 bucket name for pipeline artifacts and data.'",
          "role": "annotation=str required=True description='IAM role for pipeline execution.'",
          "region": "annotation=str required=True description='Custom region code (NA, EU, FE) for internal logic.'",
          "service_name": "annotation=str required=True description='Service name for the pipeline.'",
          "pipeline_version": "annotation=str required=True description='Version string for the SageMaker Pipeline.'",
          "model_class": "annotation=str required=False default='xgboost' description='Model class (e.g., XGBoost, PyTorch).'",
          "current_date": "annotation=str required=False default_factory=<lambda> description='Current date, typically used for versioning or pathing.'",
          "framework_version": "annotation=str required=False default='2.1.0' description='Default framework version (e.g., PyTorch).'",
          "py_version": "annotation=str required=False default='py310' description='Default Python version.'",
          "source_dir": "annotation=Union[str, NoneType] required=False default=None description='Common source directory for scripts if applicable. Can be overridden by step configs.'",
          "processing_instance_count": "annotation=int required=False default=1 description='Instance count for processing jobs' metadata=[Ge(ge=1), Le(le=10)]",
          "processing_volume_size": "annotation=int required=False default=500 description='Volume size for processing jobs in GB' metadata=[Ge(ge=10), Le(le=1000)]",
          "processing_instance_type_large": "annotation=str required=False default='ml.m5.4xlarge' description='Large instance type for processing step.'",
          "processing_instance_type_small": "annotation=str required=False default='ml.m5.2xlarge' description='Small instance type for processing step.'",
          "use_large_processing_instance": "annotation=bool required=False default=False description='Set to True to use large instance type, False for small instance type.'",
          "processing_source_dir": "annotation=Union[str, NoneType] required=False default=None description='Source directory for processing scripts. Falls back to base source_dir if not provided.'",
          "processing_entry_point": "annotation=str required=False default='dummy_training.py' description='Entry point script for dummy training.'",
          "processing_script_arguments": "annotation=Union[List[str], NoneType] required=False default=None description='Optional arguments for the processing script.'",
          "processing_framework_version": "annotation=str required=False default='1.2-1' description=\"Version of the scikit-learn framework to use in SageMaker Processing. Format: '<sklearn-version>-<build-number>'\"",
          "pretrained_model_path": "annotation=str required=False default='' description='Local path to pretrained model.tar.gz file.'",
          "hyperparameters": "annotation=ModelHyperparameters required=False default_factory=ModelHyperparameters description='Model hyperparameters to be included in the model package.'",
          "hyperparameters_s3_uri": "annotation=Union[str, NoneType] required=False default=None description='S3 URI where hyperparameters.json will be saved.'"
        },
        "model_fields_set": "<property>",
        "pipeline_description": "<property>",
        "pipeline_name": "<property>",
        "pipeline_s3_loc": "<property>",
        "script_contract": "<property>",
        "script_path": "<property>"
      }
    }
  },
  "overall_status": "PASSING",
  "metadata": {
    "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/dummy_training.py",
    "contract_mapping": "dummy_training_contract",
    "validation_timestamp": "2025-08-11T22:28:14.402825",
    "validator_version": "1.0.0"
  }
}