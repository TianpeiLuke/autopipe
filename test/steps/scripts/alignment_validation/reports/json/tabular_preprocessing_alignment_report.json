{
  "script_name": "tabular_preprocessing",
  "level1": {
    "passed": true,
    "issues": [
      {
        "severity": "INFO",
        "category": "arguments",
        "message": "Script defines config-driven argument provided by builder: --job-type (accessed as args.job_type)",
        "details": {
          "cli_argument": "job-type",
          "python_attribute": "job_type",
          "script": "tabular_preprocessing",
          "source": "builder"
        },
        "recommendation": "Argument --job-type is provided by builder - no action needed"
      },
      {
        "severity": "INFO",
        "category": "testability_compliance",
        "message": "Main function follows testability pattern with all required parameters",
        "details": {
          "script": "tabular_preprocessing",
          "testability_parameters": [
            "environ_vars",
            "input_paths",
            "job_args",
            "output_paths"
          ]
        },
        "recommendation": "No action needed - script follows testability best practices"
      },
      {
        "severity": "WARNING",
        "category": "testability_env_access",
        "message": "Helper functions use direct environment access - consider parameter passing",
        "details": {
          "script": "tabular_preprocessing",
          "helper_accesses": [
            {
              "function": null,
              "variable": "LABEL_FIELD",
              "line_number": 200
            },
            {
              "function": null,
              "variable": "TRAIN_RATIO",
              "line_number": 203
            },
            {
              "function": null,
              "variable": "TEST_VAL_RATIO",
              "line_number": 204
            }
          ]
        },
        "recommendation": "Pass environment variables as parameters to helper functions instead of direct access"
      },
      {
        "severity": "WARNING",
        "category": "testability_entry_point",
        "message": "Main function expects environ_vars parameter but no environment collection found in entry point",
        "details": {
          "script": "tabular_preprocessing"
        },
        "recommendation": "Add environment variable collection in __main__ block to pass to main function"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for job_args",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "job_args",
          "current_pattern": "job_args.job_type",
          "line_number": 134
        },
        "recommendation": "Use job_args['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 135
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 136
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 137
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for input_paths",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "input_paths",
          "current_pattern": "input_paths.get",
          "line_number": 140
        },
        "recommendation": "Use input_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for output_paths",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "output_paths",
          "current_pattern": "output_paths.get",
          "line_number": 141
        },
        "recommendation": "Use output_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for job_args",
        "details": {
          "script": "tabular_preprocessing",
          "parameter": "job_args",
          "current_pattern": "args.job_type",
          "line_number": 220
        },
        "recommendation": "Use job_args['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_container_support",
        "message": "No container detection found - consider adding hybrid mode support",
        "details": {
          "script": "tabular_preprocessing"
        },
        "recommendation": "Add container detection to support both local and container execution"
      },
      {
        "severity": "WARNING",
        "category": "testability_helper_functions",
        "message": "Helper function 'None' accesses environment directly",
        "details": {
          "script": "tabular_preprocessing",
          "function": null,
          "env_variables": [
            "LABEL_FIELD",
            "TRAIN_RATIO",
            "TEST_VAL_RATIO"
          ],
          "line_numbers": [
            200,
            203,
            204
          ]
        },
        "recommendation": "Refactor 'None' to accept environment variables as parameters"
      },
      {
        "severity": "INFO",
        "category": "framework_detected",
        "message": "Processing script uses sklearn framework",
        "details": {
          "script": "tabular_preprocessing",
          "step_type": "Processing",
          "framework": "sklearn"
        },
        "recommendation": "Ensure sklearn dependencies are properly specified"
      }
    ],
    "script_analysis": {
      "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/tabular_preprocessing.py",
      "path_references": [
        "path='.gz' line_number=22 context='\\ndef _is_gzipped(path: str) -> bool:\\n>>>     return path.lower().endswith(\".gz\")\\n\\ndef _detect_separator_from_sample(sample_lines: str) -> str:' is_hardcoded=True construction_method=None",
        "path='Use csv.Sniffer to detect a delimiter, defaulting to comma.' line_number=25 context='\\ndef _detect_separator_from_sample(sample_lines: str) -> str:\\n>>>     \"\"\"Use csv.Sniffer to detect a delimiter, defaulting to comma.\"\"\"\\n    try:\\n        dialect = csv.Sniffer().sniff(sample_lines)' is_hardcoded=True construction_method=None",
        "path='Check if the JSON file is in JSON Lines or regular format.' line_number=33 context='\\ndef peek_json_format(file_path: Path, open_func=open) -> str:\\n>>>     \"\"\"Check if the JSON file is in JSON Lines or regular format.\"\"\"\\n    try:\\n        with open_func(str(file_path), \"rt\") as f:' is_hardcoded=True construction_method=None",
        "path='Read a JSON or JSON Lines file into a DataFrame.' line_number=52 context='\\ndef _read_json_file(file_path: Path) -> pd.DataFrame:\\n>>>     \"\"\"Read a JSON or JSON Lines file into a DataFrame.\"\"\"\\n    open_func = gzip.open if _is_gzipped(str(file_path)) else open\\n    fmt = peek_json_format(file_path, open_func)' is_hardcoded=True construction_method=None",
        "path='Read a single file (CSV, TSV, JSON, Parquet) into a DataFrame.' line_number=63 context='\\ndef _read_file_to_df(file_path: Path) -> pd.DataFrame:\\n>>>     \"\"\"Read a single file (CSV, TSV, JSON, Parquet) into a DataFrame.\"\"\"\\n    suffix = file_path.suffix.lower()\\n    if suffix == \".gz\":' is_hardcoded=True construction_method=None",
        "path='.gz' line_number=65 context='    \"\"\"Read a single file (CSV, TSV, JSON, Parquet) into a DataFrame.\"\"\"\\n    suffix = file_path.suffix.lower()\\n>>>     if suffix == \".gz\":\\n        inner_ext = Path(file_path.stem).suffix.lower()\\n        if inner_ext in [\".csv\", \".tsv\"]:' is_hardcoded=True construction_method=None",
        "path='.csv' line_number=67 context='    if suffix == \".gz\":\\n        inner_ext = Path(file_path.stem).suffix.lower()\\n>>>         if inner_ext in [\".csv\", \".tsv\"]:\\n            with gzip.open(str(file_path), \"rt\") as f:\\n                sep = _detect_separator_from_sample(f.readline() + f.readline())' is_hardcoded=True construction_method=None",
        "path='.tsv' line_number=67 context='    if suffix == \".gz\":\\n        inner_ext = Path(file_path.stem).suffix.lower()\\n>>>         if inner_ext in [\".csv\", \".tsv\"]:\\n            with gzip.open(str(file_path), \"rt\") as f:\\n                sep = _detect_separator_from_sample(f.readline() + f.readline())' is_hardcoded=True construction_method=None",
        "path='.json' line_number=71 context='                sep = _detect_separator_from_sample(f.readline() + f.readline())\\n            return pd.read_csv(str(file_path), sep=sep, compression=\"gzip\")\\n>>>         elif inner_ext == \".json\":\\n            return _read_json_file(file_path)\\n        elif inner_ext.endswith(\".parquet\"):' is_hardcoded=True construction_method=None",
        "path='.csv' line_number=82 context='        else:\\n            raise ValueError(f\"Unsupported gzipped file type: {file_path}\")\\n>>>     elif suffix in [\".csv\", \".tsv\"]:\\n        with open(str(file_path), \"rt\") as f:\\n            sep = _detect_separator_from_sample(f.readline() + f.readline())' is_hardcoded=True construction_method=None",
        "path='.tsv' line_number=82 context='        else:\\n            raise ValueError(f\"Unsupported gzipped file type: {file_path}\")\\n>>>     elif suffix in [\".csv\", \".tsv\"]:\\n        with open(str(file_path), \"rt\") as f:\\n            sep = _detect_separator_from_sample(f.readline() + f.readline())' is_hardcoded=True construction_method=None",
        "path='.json' line_number=86 context='            sep = _detect_separator_from_sample(f.readline() + f.readline())\\n        return pd.read_csv(str(file_path), sep=sep)\\n>>>     elif suffix == \".json\":\\n        return _read_json_file(file_path)\\n    elif suffix.endswith(\".parquet\"):' is_hardcoded=True construction_method=None",
        "path='Detect and combine all supported data shards in a directory.' line_number=94 context='\\ndef combine_shards(input_dir: str) -> pd.DataFrame:\\n>>>     \"\"\"Detect and combine all supported data shards in a directory.\"\"\"\\n    input_path = Path(input_dir)\\n    if not input_path.is_dir():' is_hardcoded=True construction_method=None",
        "path='part-*.csv' line_number=99 context='        raise RuntimeError(f\"Input directory does not exist: {input_dir}\")\\n    patterns = [\\n>>>         \"part-*.csv\", \"part-*.csv.gz\", \"part-*.json\", \"part-*.json.gz\",\\n        \"part-*.parquet\", \"part-*.snappy.parquet\", \"part-*.parquet.gz\"\\n    ]' is_hardcoded=True construction_method=None",
        "path='part-*.csv.gz' line_number=99 context='        raise RuntimeError(f\"Input directory does not exist: {input_dir}\")\\n    patterns = [\\n>>>         \"part-*.csv\", \"part-*.csv.gz\", \"part-*.json\", \"part-*.json.gz\",\\n        \"part-*.parquet\", \"part-*.snappy.parquet\", \"part-*.parquet.gz\"\\n    ]' is_hardcoded=True construction_method=None",
        "path='part-*.json' line_number=99 context='        raise RuntimeError(f\"Input directory does not exist: {input_dir}\")\\n    patterns = [\\n>>>         \"part-*.csv\", \"part-*.csv.gz\", \"part-*.json\", \"part-*.json.gz\",\\n        \"part-*.parquet\", \"part-*.snappy.parquet\", \"part-*.parquet.gz\"\\n    ]' is_hardcoded=True construction_method=None",
        "path='part-*.json.gz' line_number=99 context='        raise RuntimeError(f\"Input directory does not exist: {input_dir}\")\\n    patterns = [\\n>>>         \"part-*.csv\", \"part-*.csv.gz\", \"part-*.json\", \"part-*.json.gz\",\\n        \"part-*.parquet\", \"part-*.snappy.parquet\", \"part-*.parquet.gz\"\\n    ]' is_hardcoded=True construction_method=None",
        "path='part-*.parquet.gz' line_number=100 context='    patterns = [\\n        \"part-*.csv\", \"part-*.csv.gz\", \"part-*.json\", \"part-*.json.gz\",\\n>>>         \"part-*.parquet\", \"part-*.snappy.parquet\", \"part-*.parquet.gz\"\\n    ]\\n    all_shards = sorted([p for pat in patterns for p in input_path.glob(pat)])' is_hardcoded=True construction_method=None",
        "path='No CSV/JSON/Parquet shards found under ' line_number=104 context='    all_shards = sorted([p for pat in patterns for p in input_path.glob(pat)])\\n    if not all_shards:\\n>>>         raise RuntimeError(f\"No CSV/JSON/Parquet shards found under {input_dir}\")\\n    try:\\n        dfs = [_read_file_to_df(shard) for shard in all_shards]' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/data' line_number=140 context='    \\n    # Extract paths\\n>>>     input_data_dir = input_paths.get(\"data_input\", \"/opt/ml/processing/input/data\")\\n    output_dir = output_paths.get(\"data_output\", \"/opt/ml/processing/output\")\\n    # Use print function if no logger is provided' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output' line_number=141 context='    # Extract paths\\n    input_data_dir = input_paths.get(\"data_input\", \"/opt/ml/processing/input/data\")\\n>>>     output_dir = output_paths.get(\"data_output\", \"/opt/ml/processing/output\")\\n    # Use print function if no logger is provided\\n    log = logger or print' is_hardcoded=True construction_method=None",
        "path='.' line_number=155 context='\\n    # 3. Process columns and labels\\n>>>     df.columns = [col.replace(\"__DOT__\", \".\") for col in df.columns]\\n    if label_field not in df.columns:\\n        raise RuntimeError(f\"Label field \\'{label_field}\\' not found in columns: {df.columns.tolist()}\")' is_hardcoded=True construction_method=None",
        "path='_processed_data.csv' line_number=183 context='        \\n        # Only output processed_data.csv\\n>>>         proc_path = subfolder / f\"{split_name}_processed_data.csv\"\\n        split_df.to_csv(proc_path, index=False)\\n        log(f\"[INFO] Saved {proc_path} (shape={split_df.shape})\")' is_hardcoded=True construction_method=None",
        "path='[INFO] Preprocessing complete.' line_number=187 context='        log(f\"[INFO] Saved {proc_path} (shape={split_df.shape})\")\\n\\n>>>     log(\"[INFO] Preprocessing complete.\")\\n    return splits\\n' is_hardcoded=True construction_method=None",
        "path='LABEL_FIELD environment variable must be set.' line_number=202 context='        LABEL_FIELD = os.environ.get(\"LABEL_FIELD\")\\n        if not LABEL_FIELD:\\n>>>             raise RuntimeError(\"LABEL_FIELD environment variable must be set.\")\\n        TRAIN_RATIO = float(os.environ.get(\"TRAIN_RATIO\", 0.7))\\n        TEST_VAL_RATIO = float(os.environ.get(\"TEST_VAL_RATIO\", 0.5))' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/data' line_number=207 context='        \\n        # Define standard SageMaker paths - use contract-declared paths directly\\n>>>         INPUT_DATA_DIR = \"/opt/ml/processing/input/data\"\\n        OUTPUT_DIR = \"/opt/ml/processing/output\"\\n        ' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output' line_number=208 context='        # Define standard SageMaker paths - use contract-declared paths directly\\n        INPUT_DATA_DIR = \"/opt/ml/processing/input/data\"\\n>>>         OUTPUT_DIR = \"/opt/ml/processing/output\"\\n        \\n        # Set up logging' is_hardcoded=True construction_method=None"
      ],
      "env_var_accesses": [
        "variable_name='LABEL_FIELD' line_number=200 context='\\n        # Read configuration from environment variables\\n>>>         LABEL_FIELD = os.environ.get(\"LABEL_FIELD\")\\n        if not LABEL_FIELD:\\n            raise RuntimeError(\"LABEL_FIELD environment variable must be set.\")' access_method='os.environ.get' has_default=False default_value=None",
        "variable_name='TRAIN_RATIO' line_number=203 context='        if not LABEL_FIELD:\\n            raise RuntimeError(\"LABEL_FIELD environment variable must be set.\")\\n>>>         TRAIN_RATIO = float(os.environ.get(\"TRAIN_RATIO\", 0.7))\\n        TEST_VAL_RATIO = float(os.environ.get(\"TEST_VAL_RATIO\", 0.5))\\n        ' access_method='os.environ.get' has_default=True default_value=None",
        "variable_name='TEST_VAL_RATIO' line_number=204 context='            raise RuntimeError(\"LABEL_FIELD environment variable must be set.\")\\n        TRAIN_RATIO = float(os.environ.get(\"TRAIN_RATIO\", 0.7))\\n>>>         TEST_VAL_RATIO = float(os.environ.get(\"TEST_VAL_RATIO\", 0.5))\\n        \\n        # Define standard SageMaker paths - use contract-declared paths directly' access_method='os.environ.get' has_default=True default_value=None"
      ],
      "imports": [
        "module_name='os' import_alias=None line_number=2 is_from_import=False imported_items=[]",
        "module_name='gzip' import_alias=None line_number=3 is_from_import=False imported_items=[]",
        "module_name='tempfile' import_alias=None line_number=4 is_from_import=False imported_items=[]",
        "module_name='shutil' import_alias=None line_number=5 is_from_import=False imported_items=[]",
        "module_name='csv' import_alias=None line_number=6 is_from_import=False imported_items=[]",
        "module_name='json' import_alias=None line_number=7 is_from_import=False imported_items=[]",
        "module_name='argparse' import_alias=None line_number=8 is_from_import=False imported_items=[]",
        "module_name='logging' import_alias=None line_number=9 is_from_import=False imported_items=[]",
        "module_name='sys' import_alias=None line_number=10 is_from_import=False imported_items=[]",
        "module_name='traceback' import_alias=None line_number=11 is_from_import=False imported_items=[]",
        "module_name='pathlib' import_alias=None line_number=12 is_from_import=True imported_items=['Path']",
        "module_name='typing' import_alias=None line_number=13 is_from_import=True imported_items=['Dict']",
        "module_name='multiprocessing' import_alias=None line_number=14 is_from_import=True imported_items=['Pool', 'cpu_count']",
        "module_name='pandas' import_alias='pd' line_number=15 is_from_import=False imported_items=[]",
        "module_name='numpy' import_alias='np' line_number=16 is_from_import=False imported_items=[]",
        "module_name='sklearn.model_selection' import_alias=None line_number=17 is_from_import=True imported_items=['train_test_split']"
      ],
      "argument_definitions": [
        "argument_name='job_type' line_number=194 is_required=True has_default=False default_value=None argument_type='str' choices=['training', 'validation', 'testing', 'calibration']"
      ],
      "file_operations": [
        "file_path='<file_object>' operation_type='read' line_number=59 context='    else:\\n        with open_func(str(file_path), \"rt\") as f:\\n>>>             data = json.load(f)\\n        return pd.json_normalize(data if isinstance(data, list) else [data])\\n' mode=None method='json.load'"
      ],
      "step_type": "Processing",
      "framework": "sklearn",
      "step_type_patterns": {}
    },
    "contract": {
      "entry_point": "tabular_preprocessing.py",
      "inputs": {
        "DATA": {
          "path": "/opt/ml/processing/input/data"
        }
      },
      "outputs": {
        "processed_data": {
          "path": "/opt/ml/processing/output"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [
          "LABEL_FIELD",
          "TRAIN_RATIO",
          "TEST_VAL_RATIO"
        ],
        "optional": {
          "CATEGORICAL_COLUMNS": "",
          "NUMERICAL_COLUMNS": "",
          "TEXT_COLUMNS": "",
          "DATE_COLUMNS": ""
        }
      },
      "description": "\n    Tabular preprocessing script that:\n    1. Combines data shards from input directory\n    2. Cleans and processes label field\n    3. Splits data into train/test/val for training jobs\n    4. Outputs processed CSV files by split\n    \n    Contract aligned with actual script implementation:\n    - Inputs: DATA (required) - reads from /opt/ml/processing/input/data\n    - Outputs: processed_data (primary) - writes to /opt/ml/processing/output\n    - Arguments: job_type (required) - defines processing mode (training/validation/testing)\n    \n    Script Implementation Details:\n    - Reads data shards (CSV, JSON, Parquet) from input/data directory\n    - Supports gzipped files and various formats\n    - Processes labels (converts categorical to numeric if needed)\n    - Splits data based on job_type (training creates train/test/val splits)\n    - Outputs processed files to split subdirectories under /opt/ml/processing/output\n    ",
      "framework_requirements": {
        "pandas": ">=1.3.0",
        "numpy": ">=1.21.0",
        "scikit-learn": ">=1.0.0"
      }
    }
  },
  "level2": {
    "passed": true,
    "issues": [
      {
        "severity": "INFO",
        "category": "multi_variant_validation",
        "message": "Smart Specification Selection: validated against 5 variants",
        "details": {
          "contract": "tabular_preprocess_contract",
          "variants": [
            "training",
            "testing",
            "validation",
            "calibration",
            "generic"
          ],
          "total_dependencies": 1,
          "total_outputs": 1,
          "contract_inputs": 1,
          "contract_outputs": 1
        },
        "recommendation": "Multi-variant validation completed successfully"
      },
      {
        "severity": "INFO",
        "category": "step_type_resolution",
        "message": "Step type resolved via registry: TabularPreprocessing_Training -> TabularPreprocessing -> Processing",
        "details": {
          "contract": "tabular_preprocess_contract",
          "original_spec_type": "TabularPreprocessing_Training",
          "canonical_name": "TabularPreprocessing",
          "resolved_sagemaker_type": "Processing",
          "registry_available": true
        },
        "recommendation": "Using Processing step property paths for validation"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation",
        "message": "Valid property path in output processed_data: properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
        "details": {
          "contract": "tabular_preprocess_contract",
          "logical_name": "processed_data",
          "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
          "step_type": "processing",
          "validation_source": "SageMaker Documentation v2.92.2",
          "documentation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference"
        },
        "recommendation": "Property path is correctly formatted for the step type"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation_summary",
        "message": "Property path validation completed for tabular_preprocess_contract",
        "details": {
          "contract": "tabular_preprocess_contract",
          "step_type": "processing",
          "node_type": "internal",
          "total_outputs": 1,
          "outputs_with_property_paths": 1,
          "validation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference",
          "documentation_version": "v2.92.2"
        },
        "recommendation": "Validated 1/1 outputs with property paths against SageMaker documentation"
      }
    ],
    "contract": {
      "entry_point": "tabular_preprocessing.py",
      "inputs": {
        "DATA": {
          "path": "/opt/ml/processing/input/data"
        }
      },
      "outputs": {
        "processed_data": {
          "path": "/opt/ml/processing/output"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [
          "LABEL_FIELD",
          "TRAIN_RATIO",
          "TEST_VAL_RATIO"
        ],
        "optional": {
          "CATEGORICAL_COLUMNS": "",
          "NUMERICAL_COLUMNS": "",
          "TEXT_COLUMNS": "",
          "DATE_COLUMNS": ""
        }
      },
      "description": "\n    Tabular preprocessing script that:\n    1. Combines data shards from input directory\n    2. Cleans and processes label field\n    3. Splits data into train/test/val for training jobs\n    4. Outputs processed CSV files by split\n    \n    Contract aligned with actual script implementation:\n    - Inputs: DATA (required) - reads from /opt/ml/processing/input/data\n    - Outputs: processed_data (primary) - writes to /opt/ml/processing/output\n    - Arguments: job_type (required) - defines processing mode (training/validation/testing)\n    \n    Script Implementation Details:\n    - Reads data shards (CSV, JSON, Parquet) from input/data directory\n    - Supports gzipped files and various formats\n    - Processes labels (converts categorical to numeric if needed)\n    - Splits data based on job_type (training creates train/test/val splits)\n    - Outputs processed files to split subdirectories under /opt/ml/processing/output\n    ",
      "framework_requirements": {
        "pandas": ">=1.3.0",
        "numpy": ">=1.21.0",
        "scikit-learn": ">=1.0.0"
      }
    },
    "specifications": {
      "tabular_preprocessing_testing_spec": {
        "step_type": "TabularPreprocessing_Testing",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw testing data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed testing data"
          }
        ]
      },
      "tabular_preprocessing_calibration_spec": {
        "step_type": "TabularPreprocessing_Calibration",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw calibration data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed calibration data for model evaluation"
          }
        ]
      },
      "tabular_preprocessing_validation_spec": {
        "step_type": "TabularPreprocessing_Validation",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw validation data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed validation data"
          }
        ]
      },
      "tabular_preprocessing_training_spec": {
        "step_type": "TabularPreprocessing_Training",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw training data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed training data with train/val/test splits"
          }
        ]
      },
      "tabular_preprocessing_spec": {
        "step_type": "TabularPreprocessing_Training",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw tabular data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed tabular data with train/val/test splits"
          }
        ]
      }
    },
    "unified_specification": {
      "primary_spec": {
        "step_type": "TabularPreprocessing_Training",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "DATA",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "ProcessingStep",
              "DataLoad",
              "CradleDataLoading"
            ],
            "data_type": "S3Uri",
            "description": "Raw training data for preprocessing"
          }
        ],
        "outputs": [
          {
            "logical_name": "processed_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Processed training data with train/val/test splits"
          }
        ]
      },
      "variants": {
        "training": {
          "step_type": "TabularPreprocessing_Training",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "DATA",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "ProcessingStep",
                "DataLoad",
                "CradleDataLoading"
              ],
              "data_type": "S3Uri",
              "description": "Raw training data for preprocessing"
            }
          ],
          "outputs": [
            {
              "logical_name": "processed_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Processed training data with train/val/test splits"
            }
          ]
        },
        "testing": {
          "step_type": "TabularPreprocessing_Testing",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "DATA",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "ProcessingStep",
                "DataLoad",
                "CradleDataLoading"
              ],
              "data_type": "S3Uri",
              "description": "Raw testing data for preprocessing"
            }
          ],
          "outputs": [
            {
              "logical_name": "processed_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Processed testing data"
            }
          ]
        },
        "validation": {
          "step_type": "TabularPreprocessing_Validation",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "DATA",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "ProcessingStep",
                "DataLoad",
                "CradleDataLoading"
              ],
              "data_type": "S3Uri",
              "description": "Raw validation data for preprocessing"
            }
          ],
          "outputs": [
            {
              "logical_name": "processed_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Processed validation data"
            }
          ]
        },
        "calibration": {
          "step_type": "TabularPreprocessing_Calibration",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "DATA",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "ProcessingStep",
                "DataLoad",
                "CradleDataLoading"
              ],
              "data_type": "S3Uri",
              "description": "Raw calibration data for preprocessing"
            }
          ],
          "outputs": [
            {
              "logical_name": "processed_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Processed calibration data for model evaluation"
            }
          ]
        },
        "generic": {
          "step_type": "TabularPreprocessing_Training",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "DATA",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "ProcessingStep",
                "DataLoad",
                "CradleDataLoading"
              ],
              "data_type": "S3Uri",
              "description": "Raw tabular data for preprocessing"
            }
          ],
          "outputs": [
            {
              "logical_name": "processed_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Processed tabular data with train/val/test splits"
            }
          ]
        }
      },
      "unified_dependencies": {
        "DATA": {
          "logical_name": "DATA",
          "dependency_type": "processing_output",
          "required": true,
          "compatible_sources": [
            "ProcessingStep",
            "DataLoad",
            "CradleDataLoading"
          ],
          "data_type": "S3Uri",
          "description": "Raw tabular data for preprocessing"
        }
      },
      "unified_outputs": {
        "processed_data": {
          "logical_name": "processed_data",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Processed tabular data with train/val/test splits"
        }
      },
      "dependency_sources": {
        "DATA": [
          "training",
          "testing",
          "validation",
          "calibration",
          "generic"
        ]
      },
      "output_sources": {
        "processed_data": [
          "training",
          "testing",
          "validation",
          "calibration",
          "generic"
        ]
      },
      "variant_count": 5
    }
  },
  "level3": {
    "passed": true,
    "issues": [],
    "specification": {
      "step_type": "TabularPreprocessing_Training",
      "node_type": "internal",
      "dependencies": [
        {
          "logical_name": "DATA",
          "dependency_type": "processing_output",
          "required": true,
          "compatible_sources": [
            "ProcessingStep",
            "DataLoad",
            "CradleDataLoading"
          ],
          "data_type": "S3Uri",
          "description": "Raw tabular data for preprocessing"
        }
      ],
      "outputs": [
        {
          "logical_name": "processed_data",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['processed_data'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Processed tabular data with train/val/test splits"
        }
      ]
    }
  },
  "level4": {
    "passed": true,
    "issues": [
      {
        "severity": "WARNING",
        "category": "configuration_fields",
        "message": "Required configuration field not accessed in builder: label_name",
        "details": {
          "field_name": "label_name",
          "builder": "tabular_preprocessing"
        },
        "recommendation": "Access required field label_name in builder or make it optional"
      },
      {
        "severity": "INFO",
        "category": "required_field_validation",
        "message": "Builder has required fields but no explicit validation logic detected",
        "details": {
          "required_fields": [
            "label_name"
          ],
          "builder": "tabular_preprocessing"
        },
        "recommendation": "Consider adding explicit validation logic for required configuration fields"
      }
    ],
    "builder_analysis": {
      "config_accesses": [
        {
          "field_name": "job_type",
          "line_number": 65,
          "context": "line_65"
        }
      ],
      "validation_calls": [],
      "default_assignments": [],
      "class_definitions": [
        {
          "class_name": "TabularPreprocessingStepBuilder",
          "line_number": 29,
          "base_classes": [
            "StepBuilderBase"
          ],
          "decorators": [
            "Call"
          ]
        }
      ],
      "method_definitions": [
        {
          "method_name": "__init__",
          "line_number": 37,
          "args": [
            "self",
            "config",
            "sagemaker_session",
            "role",
            "notebook_root",
            "registry_manager",
            "dependency_resolver"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "validate_configuration",
          "line_number": 98,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_create_processor",
          "line_number": 125,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_environment_variables",
          "line_number": 145,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_inputs",
          "line_number": 173,
          "args": [
            "self",
            "inputs"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_outputs",
          "line_number": 226,
          "args": [
            "self",
            "outputs"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_job_arguments",
          "line_number": 281,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "create_step",
          "line_number": 301,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        }
      ],
      "import_statements": [
        {
          "type": "from_import",
          "module": "typing",
          "name": "Dict",
          "alias": null,
          "line_number": 1
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Optional",
          "alias": null,
          "line_number": 1
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Any",
          "alias": null,
          "line_number": 1
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "List",
          "alias": null,
          "line_number": 1
        },
        {
          "type": "from_import",
          "module": "pathlib",
          "name": "Path",
          "alias": null,
          "line_number": 2
        },
        {
          "type": "import",
          "module": "logging",
          "alias": null,
          "line_number": 3
        },
        {
          "type": "import",
          "module": "importlib",
          "alias": null,
          "line_number": 4
        },
        {
          "type": "from_import",
          "module": "sagemaker.workflow.steps",
          "name": "ProcessingStep",
          "alias": null,
          "line_number": 6
        },
        {
          "type": "from_import",
          "module": "sagemaker.workflow.steps",
          "name": "Step",
          "alias": null,
          "line_number": 6
        },
        {
          "type": "from_import",
          "module": "sagemaker.processing",
          "name": "ProcessingInput",
          "alias": null,
          "line_number": 7
        },
        {
          "type": "from_import",
          "module": "sagemaker.processing",
          "name": "ProcessingOutput",
          "alias": null,
          "line_number": 7
        },
        {
          "type": "from_import",
          "module": "sagemaker.sklearn",
          "name": "SKLearnProcessor",
          "alias": null,
          "line_number": 8
        },
        {
          "type": "from_import",
          "module": "configs.config_tabular_preprocessing_step",
          "name": "TabularPreprocessingConfig",
          "alias": null,
          "line_number": 10
        },
        {
          "type": "from_import",
          "module": "core.base.builder_base",
          "name": "StepBuilderBase",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "registry.builder_registry",
          "name": "register_builder",
          "alias": null,
          "line_number": 12
        },
        {
          "type": "from_import",
          "module": "specs.tabular_preprocessing_training_spec",
          "name": "TABULAR_PREPROCESSING_TRAINING_SPEC",
          "alias": null,
          "line_number": 16
        },
        {
          "type": "from_import",
          "module": "specs.tabular_preprocessing_calibration_spec",
          "name": "TABULAR_PREPROCESSING_CALIBRATION_SPEC",
          "alias": null,
          "line_number": 17
        },
        {
          "type": "from_import",
          "module": "specs.tabular_preprocessing_validation_spec",
          "name": "TABULAR_PREPROCESSING_VALIDATION_SPEC",
          "alias": null,
          "line_number": 18
        },
        {
          "type": "from_import",
          "module": "specs.tabular_preprocessing_testing_spec",
          "name": "TABULAR_PREPROCESSING_TESTING_SPEC",
          "alias": null,
          "line_number": 19
        }
      ],
      "config_class_usage": []
    },
    "config_analysis": {
      "class_name": "TabularPreprocessingConfig",
      "fields": {
        "label_name": {
          "type": "<class 'str'>",
          "required": true
        },
        "processing_entry_point": {
          "type": "<class 'str'>",
          "required": false
        },
        "job_type": {
          "type": "<class 'str'>",
          "required": false
        },
        "train_ratio": {
          "type": "<class 'float'>",
          "required": false
        },
        "test_val_ratio": {
          "type": "<class 'float'>",
          "required": false
        },
        "_full_script_path": {
          "type": "typing.Optional[str]",
          "required": false
        }
      },
      "required_fields": [
        "label_name"
      ],
      "optional_fields": [
        "_full_script_path",
        "job_type",
        "processing_entry_point",
        "test_val_ratio",
        "train_ratio"
      ],
      "default_values": {
        "aws_region": "<property>",
        "effective_instance_type": "<property>",
        "effective_source_dir": "<property>",
        "full_script_path": "<property>",
        "model_computed_fields": {},
        "model_config": {
          "arbitrary_types_allowed": true,
          "extra": "allow",
          "protected_namespaces": [],
          "validate_assignment": true
        },
        "model_extra": "<property>",
        "model_fields": {
          "author": "annotation=str required=True description='Author or owner of the pipeline.'",
          "bucket": "annotation=str required=True description='S3 bucket name for pipeline artifacts and data.'",
          "role": "annotation=str required=True description='IAM role for pipeline execution.'",
          "region": "annotation=str required=True description='Custom region code (NA, EU, FE) for internal logic.'",
          "service_name": "annotation=str required=True description='Service name for the pipeline.'",
          "pipeline_version": "annotation=str required=True description='Version string for the SageMaker Pipeline.'",
          "model_class": "annotation=str required=False default='xgboost' description='Model class (e.g., XGBoost, PyTorch).'",
          "current_date": "annotation=str required=False default_factory=<lambda> description='Current date, typically used for versioning or pathing.'",
          "framework_version": "annotation=str required=False default='2.1.0' description='Default framework version (e.g., PyTorch).'",
          "py_version": "annotation=str required=False default='py310' description='Default Python version.'",
          "source_dir": "annotation=Union[str, NoneType] required=False default=None description='Common source directory for scripts if applicable. Can be overridden by step configs.'",
          "processing_instance_count": "annotation=int required=False default=1 description='Instance count for processing jobs' metadata=[Ge(ge=1), Le(le=10)]",
          "processing_volume_size": "annotation=int required=False default=500 description='Volume size for processing jobs in GB' metadata=[Ge(ge=10), Le(le=1000)]",
          "processing_instance_type_large": "annotation=str required=False default='ml.m5.4xlarge' description='Large instance type for processing step.'",
          "processing_instance_type_small": "annotation=str required=False default='ml.m5.2xlarge' description='Small instance type for processing step.'",
          "use_large_processing_instance": "annotation=bool required=False default=False description='Set to True to use large instance type, False for small instance type.'",
          "processing_source_dir": "annotation=Union[str, NoneType] required=False default=None description='Source directory for processing scripts. Falls back to base source_dir if not provided.'",
          "processing_entry_point": "annotation=str required=False default='tabular_preprocessing.py' description='Relative path (within processing_source_dir) to the tabular preprocessing script.'",
          "processing_script_arguments": "annotation=Union[List[str], NoneType] required=False default=None description='Optional arguments for the processing script.'",
          "processing_framework_version": "annotation=str required=False default='1.2-1' description=\"Version of the scikit-learn framework to use in SageMaker Processing. Format: '<sklearn-version>-<build-number>'\"",
          "label_name": "annotation=str required=True description='Label field name for the target variable.'",
          "job_type": "annotation=str required=False default='training' description=\"One of ['training','validation','testing','calibration']\"",
          "train_ratio": "annotation=float required=False default=0.7 description=\"Fraction of data to allocate to the training set (only used if job_type=='training').\" metadata=[Ge(ge=0.0), Le(le=1.0)]",
          "test_val_ratio": "annotation=float required=False default=0.5 description=\"Fraction of the holdout to allocate to the test set vs. validation (only if job_type=='training').\" metadata=[Ge(ge=0.0), Le(le=1.0)]"
        },
        "model_fields_set": "<property>",
        "pipeline_description": "<property>",
        "pipeline_name": "<property>",
        "pipeline_s3_loc": "<property>",
        "script_contract": "<property>",
        "script_path": "<property>"
      }
    }
  },
  "overall_status": "PASSING",
  "metadata": {
    "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/tabular_preprocessing.py",
    "contract_mapping": "tabular_preprocessing_contract",
    "validation_timestamp": "2025-08-14T10:24:23.521892",
    "validator_version": "1.0.0"
  }
}